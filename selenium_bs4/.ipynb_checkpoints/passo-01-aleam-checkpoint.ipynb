{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modulo time aqui foi utilizado para esperar o carregamento das paginas atraves do firefox\n",
    "import time\n",
    " \n",
    "# o modulo webdriver e necessario para definir qual navegador sera utilizado para fazer a automacao\n",
    "from selenium import webdriver\n",
    " \n",
    "# o modulo Select sera utilizado para interagir com a caixa de selecao onde sera definido o ano em que quero buscar os dados\n",
    "from selenium.webdriver.support.ui import Select\n",
    " \n",
    "# esse modulo sera utilizado para \n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "# a linha abaixo define qual e o navegador que queremos utilizar,\n",
    "# lembrando que eu instalei somente o driver para conexao com o firefox,\n",
    "#mas existem tambem para Chrome e InternetExplorer\n",
    "#driver = webdriver.Firefox()\n",
    "driver = webdriver.Chrome()\n",
    " \n",
    "# abaixo foi definido qual e o site que quero acessar\n",
    "driver.get(\"http://www.ale.am.gov.br/tipos-publicacoes/prestacao-contas/\")\n",
    " \n",
    "# o Sleep abaixo e para aguardar o carregamento da pagina\n",
    "time.sleep(10)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora quero as receitas desde 2013 ate 2017\n",
    "anos = [\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ano in anos:\n",
    "    select_ano = Select(driver.find_element_by_xpath('//*[@id=\"main\"]/div[2]/form/div[1]/div/select'))\n",
    "    select_ano.select_by_value(ano)\n",
    "    time.sleep(5)\n",
    "    consultar = driver.find_element_by_id(\"btn_submit\")\n",
    "    consultar.click()\n",
    "    time.sleep(10)\n",
    "    dados = driver.find_element_by_xpath('//*[@id=\"main\"]/div[3]')\n",
    "    html = dados.get_attribute(\"innerHTML\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.select_one('table')\n",
    "    headers = [header.text+\"|\" for header in table.select(\"tr th\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nome|', 'Ano|', 'MÃªs|']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-77dae84161c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlinha\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "#article.find('iframe', class_='youtube-player')['src']\n",
    "\n",
    "line = []\n",
    "data = [d for d in table.select(\"tr\")]\n",
    "for d in data:\n",
    "    linha = \"\"\n",
    "    for t in d.select(\"td\"):\n",
    "        link = t.find('a')\n",
    "        if link != None:\n",
    "            #print(link['href'])\n",
    "            #print(link.get('ng-href'))\n",
    "            linha += '{};'.format(link['href'])\n",
    "        \n",
    "        linha += t.text+\";\"\n",
    "    \n",
    "    line.append(linha.replace(linha[len(linha)-1],''))\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfor a in anos:\\n    # aqui e utilizado o modulo Select do selenium para interagir com o ComboBox\\n    select = Select(driver.find_element_by_name(\"exe\"))\\n \\n    # aqui e alterado o valor do ComboBox\\n    select.select_by_value(a)\\n    # agora e buscado o elemento cujo o ID e igual a imgFiltrar\\n    filtrar = driver.find_element_by_id(\\'imgFiltrar\\')\\n    # retornado o elemento da busca e clicado no botao\\n    filtrar.click()\\n    # aguardando o carregamento da tabela\\n    time.sleep(3)\\n \\n    # armazenando a div que possui a tabela dentro da variavel dados\\n    dados = driver.find_element_by_id(\"bd10\")\\n \\n    # aqui e pegado o codigo HTML que esta dentro da div bd01 no codigo que foi mostrado acima\\n    html = dados.get_attribute(\"innerHTML\")\\n \\n    # com o codigo HTML dentro da variavel, vamos usar o BeautifulSoup para fazer o parser desse HTML\\n    soup = BeautifulSoup(html, \"html.parser\")\\n \\n    # dentro da variavel soup temos o codigo html retornado pelo Selenium ja convertido para o BS\\n    # vou utilizar o metodo select_one para buscar o elemento table dentro desse codigo\\n    table = soup.select_one(\"table\")\\n \\n    # no conteudo dessa tabela temos varias virgulas e espacos, como vou converter esses dados pra csv, vou definir o delimitador com o caracter |\\n    # na linha abaixo estou buscando todos os elementos tr, que possui a classe Grid_title e os elementos filhos cujo a tag e td\\n    # e feito um list comprehesion para pegar somente os elementos e eles estao sendo separados pelo caracter |\\n \\n    headers = [header.text+\"|\" for header in table.select(\"tr.Grid_title td\")]\\n \\n    # abaixo estou buscando os elementos tr que possuem a classe Grid_line no css\\n    # e um novo list comprehension para criar uma lista somente com o s elementos que eu quero\\n    line = []\\n    data = [d for d in table.select(\"tr.Grid_line\")]\\n    for d in data:\\n        linha = \"\"\\n        for t in d.select(\"td\"):\\n            linha += t.text+\"|\"\\n        line.append(linha)\\n \\n    # aqui e a mesma coisa que acima porem com a classe Grid_line_even\\n    line_even = []\\n    data = [ d for d in table.select(\"tr.Grid_line_even\")]\\n    for d in data:\\n        linha = \"\"\\n        for t in d.select(\"td\"):\\n            linha += t.text+\"|\"\\n        line_even.append(linha)\\n \\n    # agora que os dados ja foram parseados, vou fazer a escrita do arquivo CSV\\n    with open(\"%s.csv\"%a,\"w\") as f:\\n        s = \"\".join(headers)\\n        f.write(s+\"\\n\")\\n \\n        for l in line:\\n            f.write(l+\"\\n\")\\n \\n        for l in line_even:\\n            f.write(l+\"\\n\")\\n            \\n            \\n            \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "for a in anos:\n",
    "    # aqui e utilizado o modulo Select do selenium para interagir com o ComboBox\n",
    "    select = Select(driver.find_element_by_name(\"exe\"))\n",
    " \n",
    "    # aqui e alterado o valor do ComboBox\n",
    "    select.select_by_value(a)\n",
    "    # agora e buscado o elemento cujo o ID e igual a imgFiltrar\n",
    "    filtrar = driver.find_element_by_id('imgFiltrar')\n",
    "    # retornado o elemento da busca e clicado no botao\n",
    "    filtrar.click()\n",
    "    # aguardando o carregamento da tabela\n",
    "    time.sleep(3)\n",
    " \n",
    "    # armazenando a div que possui a tabela dentro da variavel dados\n",
    "    dados = driver.find_element_by_id(\"bd10\")\n",
    " \n",
    "    # aqui e pegado o codigo HTML que esta dentro da div bd01 no codigo que foi mostrado acima\n",
    "    html = dados.get_attribute(\"innerHTML\")\n",
    " \n",
    "    # com o codigo HTML dentro da variavel, vamos usar o BeautifulSoup para fazer o parser desse HTML\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    " \n",
    "    # dentro da variavel soup temos o codigo html retornado pelo Selenium ja convertido para o BS\n",
    "    # vou utilizar o metodo select_one para buscar o elemento table dentro desse codigo\n",
    "    table = soup.select_one(\"table\")\n",
    " \n",
    "    # no conteudo dessa tabela temos varias virgulas e espacos, como vou converter esses dados pra csv, vou definir o delimitador com o caracter |\n",
    "    # na linha abaixo estou buscando todos os elementos tr, que possui a classe Grid_title e os elementos filhos cujo a tag e td\n",
    "    # e feito um list comprehesion para pegar somente os elementos e eles estao sendo separados pelo caracter |\n",
    " \n",
    "    headers = [header.text+\"|\" for header in table.select(\"tr.Grid_title td\")]\n",
    " \n",
    "    # abaixo estou buscando os elementos tr que possuem a classe Grid_line no css\n",
    "    # e um novo list comprehension para criar uma lista somente com o s elementos que eu quero\n",
    "    line = []\n",
    "    data = [d for d in table.select(\"tr.Grid_line\")]\n",
    "    for d in data:\n",
    "        linha = \"\"\n",
    "        for t in d.select(\"td\"):\n",
    "            linha += t.text+\"|\"\n",
    "        line.append(linha)\n",
    " \n",
    "    # aqui e a mesma coisa que acima porem com a classe Grid_line_even\n",
    "    line_even = []\n",
    "    data = [ d for d in table.select(\"tr.Grid_line_even\")]\n",
    "    for d in data:\n",
    "        linha = \"\"\n",
    "        for t in d.select(\"td\"):\n",
    "            linha += t.text+\"|\"\n",
    "        line_even.append(linha)\n",
    " \n",
    "    # agora que os dados ja foram parseados, vou fazer a escrita do arquivo CSV\n",
    "    with open(\"%s.csv\"%a,\"w\") as f:\n",
    "        s = \"\".join(headers)\n",
    "        f.write(s+\"\\n\")\n",
    " \n",
    "        for l in line:\n",
    "            f.write(l+\"\\n\")\n",
    " \n",
    "        for l in line_even:\n",
    "            f.write(l+\"\\n\")\n",
    "            \n",
    "            \n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fim \n",
    "time.sleep(10)\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
